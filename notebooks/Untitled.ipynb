{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235440ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a7655b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../src/dataset/all_training_data/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cf7ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(path, exts):\n",
    "    file_names = []\n",
    "    for maindir, subdir, file_name_list in os.walk(path):\n",
    "        for filename in file_name_list:\n",
    "            file_path = os.path.join(maindir, filename)\n",
    "            ext = os.path.splitext(file_path)[1]\n",
    "            if ext not in exts:\n",
    "                file_names.append(file_path)\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a6c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, \"r\") as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211fcb9",
   "metadata": {},
   "source": [
    "#### Training statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174642c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "train_jsons = get_file_list(data_path, ['.txt'])\n",
    "print(len(train_jsons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6119ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of utterances [738, 1283, 336, 557, 415, 755, 1364, 901, 1215, 593, 985, 249, 126, 648, 649, 1143, 934, 915, 358, 856, 1207, 1082, 542, 563, 960, 524, 196, 450, 357, 1487, 672, 718, 396, 647, 973, 689, 585, 1275, 860, 839, 357, 379, 838, 782, 897, 1095, 806, 717, 924, 754, 339, 1318, 669, 722, 212, 672, 765, 497, 1207, 667, 641, 772, 1377, 1057, 572, 471, 791, 486, 614, 815, 229, 515, 886, 345, 1047, 1148, 422, 547]\n",
      "Mean utterances by dialogue 735.8205128205128\n",
      "Mean text length 7.855559814614768\n"
     ]
    }
   ],
   "source": [
    "nbr_utterances = []\n",
    "text_length = []\n",
    "\n",
    "for json_path in train_jsons:\n",
    "    json_dict = load_json(json_path)\n",
    "    nbr_utterances.append(len(json_dict))\n",
    "    text_length.extend([len(utt['text'].split(' ')) for utt in json_dict])\n",
    "\n",
    "print('Number of utterances', nbr_utterances)\n",
    "print('Mean utterances by dialogue', np.mean(nbr_utterances))\n",
    "print('Mean text length', np.mean(text_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efc155",
   "metadata": {},
   "source": [
    "###  Train / val split  0.8 vs 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5d27b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55 18 63 25 16 66 54 58 85 34 74 29 51 91 19 17 21 64 59]\n",
      "19\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 56, 57, 60, 61, 62, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96]\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "val_indices = rng.choice(len(train_jsons), \n",
    "                         size=int(0.2 * len(train_jsons)),\n",
    "                         replace=False, shuffle=False)\n",
    "print(val_indices)\n",
    "print(len(val_indices))\n",
    "\n",
    "train_indices = [idx for idx in range(len(train_jsons)) \\\n",
    "                    if idx not in val_indices]\n",
    "print(train_indices)\n",
    "print(len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5419646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean nbr of utts 801.5263157894736\n",
      "Mean text length 34.34565631361219\n"
     ]
    }
   ],
   "source": [
    "val_nbr_utterances = []\n",
    "val_text_length = []\n",
    "\n",
    "for idx in val_indices:\n",
    "    json_dict = load_json(train_jsons[idx])\n",
    "    val_nbr_utterances.append(len(json_dict))\n",
    "    val_text_length.extend([len(utt['text']) for utt in json_dict])\n",
    "    \n",
    "print('Mean nbr of utts', np.mean(val_nbr_utterances))\n",
    "print('Mean text length', np.mean(val_text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb007fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = [train_jsons[idx].split('/')[-1].split('.')[0] \n",
    "             for idx in val_indices]\n",
    "train_files = [train_jsons[idx].split('/')[-1].split('.')[0]\n",
    "               for idx in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7690fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../data/train/cust')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('../data/train/')\n",
    "path / 'cust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83b55c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val mean 0.20060656738816532\n",
      "Train mean 0.19130426494393424\n"
     ]
    }
   ],
   "source": [
    "bin_labels_dict = load_json('../dataset/training_labels.json')\n",
    "\n",
    "val_mean = []\n",
    "train_mean = []\n",
    "\n",
    "for k, v in bin_labels_dict.items():\n",
    "    if k in val_files:\n",
    "        val_mean.append(np.mean(v))\n",
    "    else:\n",
    "        train_mean.append(np.mean(v))\n",
    "        \n",
    "print('Val mean', np.mean(val_mean))\n",
    "print('Train mean', np.mean(train_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68a28090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i wlaked in caar'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'I WlaKed in CAAR'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637f90d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package               Version\r\n",
      "--------------------- ----------\r\n",
      "certifi               2023.11.17\r\n",
      "charset-normalizer    3.3.2\r\n",
      "click                 8.1.7\r\n",
      "filelock              3.13.1\r\n",
      "fsspec                2023.12.0\r\n",
      "huggingface-hub       0.19.4\r\n",
      "idna                  3.6\r\n",
      "Jinja2                3.1.2\r\n",
      "joblib                1.3.2\r\n",
      "jsonargparse          4.27.1\r\n",
      "MarkupSafe            2.1.3\r\n",
      "mpmath                1.3.0\r\n",
      "networkx              3.2.1\r\n",
      "nltk                  3.8.1\r\n",
      "numpy                 1.26.2\r\n",
      "packaging             23.2\r\n",
      "Pillow                10.1.0\r\n",
      "pip                   22.0.4\r\n",
      "PyYAML                6.0.1\r\n",
      "regex                 2023.10.3\r\n",
      "requests              2.31.0\r\n",
      "safetensors           0.4.1\r\n",
      "scikit-learn          1.3.2\r\n",
      "scipy                 1.11.4\r\n",
      "sentence-transformers 2.2.2\r\n",
      "sentencepiece         0.1.99\r\n",
      "setuptools            58.1.0\r\n",
      "sympy                 1.12\r\n",
      "threadpoolctl         3.2.0\r\n",
      "tokenizers            0.15.0\r\n",
      "torch                 2.1.1\r\n",
      "torchsummary          1.5.1\r\n",
      "torchvision           0.16.1\r\n",
      "tqdm                  4.66.1\r\n",
      "transformers          4.35.2\r\n",
      "typing_extensions     4.8.0\r\n",
      "urllib3               2.1.0\r\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8c3efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5829fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (4.35.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: requests in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/petrshulzhenko/3-year-ecole/ml-intro/inf554-extractive-summarization-2023/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced71954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "outputs.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
